{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copie de NLP_Week4_Exercise_Shakespeare_Answer.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/NLP_Week4_Exercise_Shakespeare_Answer.ipynb","timestamp":1568460130890},{"file_id":"1qmXwwCaT07-qviCiBV65lkus_KvwsyQI","timestamp":1559583256599},{"file_id":"1V60jn23JMcMpwhF-KvCTYIIfm4J2X6v5","timestamp":1558728367158}]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"BOwsuGQQY9OL","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","import tensorflow.keras.utils as ku \n","import numpy as np "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PRnDnCW-Z7qv","outputId":"9fa575aa-e48a-4ee1-91fb-2d819d12a35c","executionInfo":{"status":"ok","timestamp":1568460065550,"user_tz":-120,"elapsed":8067,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["tokenizer = Tokenizer()\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n","    -O /tmp/sonnets.txt\n","data = open('/tmp/sonnets.txt').read()\n","\n","corpus = data.lower().split(\"\\n\")\n","\n","\n","tokenizer.fit_on_texts(corpus)\n","total_words = len(tokenizer.word_index) + 1\n","\n","# create input sequences using list of tokens\n","input_sequences = []\n","for line in corpus:\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\t\tinput_sequences.append(n_gram_sequence)\n","\n","\n","# pad sequences \n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# create predictors and label\n","predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n","\n","label = ku.to_categorical(label, num_classes=total_words)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-09-14 11:20:59--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.184.128, 2a00:1450:400c:c00::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.184.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 93578 (91K) [text/plain]\n","Saving to: ‘/tmp/sonnets.txt’\n","\n","/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n","\n","2019-09-14 11:21:04 (137 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w9vH8Y59ajYL","colab_type":"code","outputId":"500888e5-5862-4f36-d3fd-ad99acc606fb","executionInfo":{"status":"ok","timestamp":1568460074076,"user_tz":-120,"elapsed":1835,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":658}},"source":["model = Sequential()\n","model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(150, return_sequences = True)))\n","model.add(Dropout(0.2))\n","model.add(LSTM(100))\n","model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model.add(Dense(total_words, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0914 11:21:12.957715 140297285183360 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/initializers.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0914 11:21:12.989269 140297285183360 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0914 11:21:13.002021 140297285183360 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0914 11:21:13.003449 140297285183360 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0914 11:21:13.008737 140297285183360 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 10, 100)           321100    \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 10, 300)           301200    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 10, 300)           0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 100)               160400    \n","_________________________________________________________________\n","dense (Dense)                (None, 1605)              162105    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3211)              5156866   \n","=================================================================\n","Total params: 6,101,671\n","Trainable params: 6,101,671\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AIg2f1HBxqof","colab_type":"code","outputId":"44631242-e1d8-4b4a-954c-b84e216189fe","colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["history = model.fit(predictors, label, epochs=100, verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0914 11:21:19.021657 140297285183360 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","15462/15462 [==============================] - 42s 3ms/sample - loss: 6.8981 - acc: 0.0211\n","Epoch 2/100\n"," 1472/15462 [=>............................] - ETA: 36s - loss: 6.4074 - acc: 0.0177"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1fXTEO3GJ282","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['acc']\n","loss = history.history['loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training accuracy')\n","plt.title('Training accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.title('Training loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Vc6PHgxa6Hm","colab_type":"code","colab":{}},"source":["seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n","next_words = 100\n","  \n","for _ in range(next_words):\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\tpredicted = model.predict_classes(token_list, verbose=0)\n","\toutput_word = \"\"\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"],"execution_count":0,"outputs":[]}]}