{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercise4-Question.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EYvXP-vxC4dl","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import os\n","import zipfile\n","import urllib\n","urllib.request.urlretrieve(\"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\",\n","                           filename=\"/tmp/happy-or-sad.zip\")\n","\n","zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n","zip_ref.extractall(\"/tmp/h-or-s\")\n","zip_ref.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HBKqiNkJDFhU","colab_type":"text"},"source":["We're going to reate a convolutional neural network that trains to 100% accuracy on these images download below and which cancels training upon hitting training accuracy of >.999"]},{"cell_type":"code","metadata":{"id":"fa03SNqEDEuP","colab_type":"code","colab":{}},"source":["DESIRED_ACCURACY = 0.999\n","\n","class StopTrainingCallback(tf.keras.callbacks.Callback):\n","  \n","  def on_epoch_end(self, epoch, logs=None):\n","    if logs.get('acc') >= DESIRED_ACCURACY:\n","      print(f'\\nReached {DESIRED_ACCURACY} accuracy so canceling training!')\n","      self.model.stop_training = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4fpADGpD2-L","colab_type":"code","outputId":"aedcc661-a142-427c-8000-0dcc6f811d8a","executionInfo":{"status":"ok","timestamp":1566222390685,"user_tz":-120,"elapsed":1572,"user":{"displayName":"Dimitri K. Sifoua","photoUrl":"https://lh6.googleusercontent.com/-7Sd8eE-A2wU/AAAAAAAAAAI/AAAAAAAACBE/9MnvPu31X0c/s64/photo.jpg","userId":"10657980328019157708"}},"colab":{"base_uri":"https://localhost:8080/","height":557}},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(300, 300, 3)),\n","    tf.keras.layers.MaxPool2D(2),\n","    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPool2D(2),\n","    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'),\n","    tf.keras.layers.MaxPool2D(2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(units=128, activation='relu'),\n","    tf.keras.layers.Dense(units=1, activation='sigmoid')\n","])\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0819 13:47:21.340875 140518546093952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 300, 300, 16)      448       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 150, 150, 16)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 150, 150, 32)      4640      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 75, 75, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 37, 37, 64)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 87616)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               11214976  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 11,238,689\n","Trainable params: 11,238,689\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MOWOcCvGFMf7","colab_type":"code","outputId":"6ffb3292-43c7-4e5c-e5b2-5c4704559ae8","executionInfo":{"status":"ok","timestamp":1566222394678,"user_tz":-120,"elapsed":1582,"user":{"displayName":"Dimitri K. Sifoua","photoUrl":"https://lh6.googleusercontent.com/-7Sd8eE-A2wU/AAAAAAAAAAI/AAAAAAAACBE/9MnvPu31X0c/s64/photo.jpg","userId":"10657980328019157708"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0819 13:47:25.364413 140518546093952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ISf3Ep05FjRK","colab_type":"code","outputId":"47c7df3d-ba03-44ec-f679-3b596e049ce8","executionInfo":{"status":"ok","timestamp":1566222459965,"user_tz":-120,"elapsed":767,"user":{"displayName":"Dimitri K. Sifoua","photoUrl":"https://lh6.googleusercontent.com/-7Sd8eE-A2wU/AAAAAAAAAAI/AAAAAAAACBE/9MnvPu31X0c/s64/photo.jpg","userId":"10657980328019157708"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["%%time\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow_from_directory(\n","                    '/tmp/h-or-s',\n","                    target_size=(300, 300),\n","                    batch_size=2,\n","                    class_mode='binary')\n","history = model.fit_generator(train_generator, steps_per_epoch=8, epochs=15, callbacks=[StopTrainingCallback()])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 80 images belonging to 2 classes.\n","Epoch 1/15\n","5/8 [=================>............] - ETA: 0s - loss: 0.0070 - acc: 1.0000    \n","Reached 0.999 accuracy so canceling training!\n","8/8 [==============================] - 0s 17ms/step - loss: 0.0055 - acc: 1.0000\n","CPU times: user 225 ms, sys: 23.4 ms, total: 248 ms\n","Wall time: 250 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IXjRV8EUGnzD","colab_type":"code","outputId":"a5302fd9-917a-4516-87ed-a2273fa1dacf","executionInfo":{"status":"ok","timestamp":1566221982545,"user_tz":-120,"elapsed":416,"user":{"displayName":"Dimitri K. Sifoua","photoUrl":"https://lh6.googleusercontent.com/-7Sd8eE-A2wU/AAAAAAAAAAI/AAAAAAAACBE/9MnvPu31X0c/s64/photo.jpg","userId":"10657980328019157708"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# help(tf.keras.models.Model.fit_generator)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Help on function fit_generator in module tensorflow.python.keras.engine.training:\n","\n","fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n","    Fits the model on data yielded batch-by-batch by a Python generator.\n","    \n","    The generator is run in parallel to the model, for efficiency.\n","    For instance, this allows you to do real-time data augmentation\n","    on images on CPU in parallel to training your model on GPU.\n","    \n","    The use of `keras.utils.Sequence` guarantees the ordering\n","    and guarantees the single use of every input per epoch when\n","    using `use_multiprocessing=True`.\n","    \n","    Arguments:\n","        generator: A generator or an instance of `Sequence`\n","          (`keras.utils.Sequence`)\n","            object in order to avoid duplicate data\n","            when using multiprocessing.\n","            The output of the generator must be either\n","            - a tuple `(inputs, targets)`\n","            - a tuple `(inputs, targets, sample_weights)`.\n","            This tuple (a single output of the generator) makes a single batch.\n","            Therefore, all arrays in this tuple must have the same length (equal\n","            to the size of this batch). Different batches may have different\n","              sizes.\n","            For example, the last batch of the epoch is commonly smaller than\n","              the\n","            others, if the size of the dataset is not divisible by the batch\n","              size.\n","            The generator is expected to loop over its data\n","            indefinitely. An epoch finishes when `steps_per_epoch`\n","            batches have been seen by the model.\n","        steps_per_epoch: Total number of steps (batches of samples)\n","            to yield from `generator` before declaring one epoch\n","            finished and starting the next epoch. It should typically\n","            be equal to the number of samples of your dataset\n","            divided by the batch size.\n","            Optional for `Sequence`: if unspecified, will use\n","            the `len(generator)` as a number of steps.\n","        epochs: Integer, total number of iterations on the data.\n","        verbose: Verbosity mode, 0, 1, or 2.\n","        callbacks: List of callbacks to be called during training.\n","        validation_data: This can be either\n","            - a generator for the validation data\n","            - a tuple (inputs, targets)\n","            - a tuple (inputs, targets, sample_weights).\n","        validation_steps: Only relevant if `validation_data`\n","            is a generator. Total number of steps (batches of samples)\n","            to yield from `generator` before stopping.\n","            Optional for `Sequence`: if unspecified, will use\n","            the `len(validation_data)` as a number of steps.\n","        validation_freq: Only relevant if validation data is provided. Integer\n","            or `collections.Container` instance (e.g. list, tuple, etc.). If an\n","            integer, specifies how many training epochs to run before a new\n","            validation run is performed, e.g. `validation_freq=2` runs\n","            validation every 2 epochs. If a Container, specifies the epochs on\n","            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n","            validation at the end of the 1st, 2nd, and 10th epochs.\n","        class_weight: Dictionary mapping class indices to a weight\n","            for the class.\n","        max_queue_size: Integer. Maximum size for the generator queue.\n","            If unspecified, `max_queue_size` will default to 10.\n","        workers: Integer. Maximum number of processes to spin up\n","            when using process-based threading.\n","            If unspecified, `workers` will default to 1. If 0, will\n","            execute the generator on the main thread.\n","        use_multiprocessing: Boolean.\n","            If `True`, use process-based threading.\n","            If unspecified, `use_multiprocessing` will default to `False`.\n","            Note that because this implementation relies on multiprocessing,\n","            you should not pass non-picklable arguments to the generator\n","            as they can't be passed easily to children processes.\n","        shuffle: Boolean. Whether to shuffle the order of the batches at\n","            the beginning of each epoch. Only used with instances\n","            of `Sequence` (`keras.utils.Sequence`).\n","            Has no effect when `steps_per_epoch` is not `None`.\n","        initial_epoch: Epoch at which to start training\n","            (useful for resuming a previous training run)\n","    \n","    Returns:\n","        A `History` object.\n","    \n","    Example:\n","    \n","    ```python\n","        def generate_arrays_from_file(path):\n","            while 1:\n","                f = open(path)\n","                for line in f:\n","                    # create numpy arrays of input data\n","                    # and labels, from each line in the file\n","                    x1, x2, y = process_line(line)\n","                    yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n","                f.close()\n","    \n","        model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n","                            steps_per_epoch=10000, epochs=10)\n","    ```\n","    Raises:\n","        ValueError: In case the generator yields data in an invalid format.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f5BGbQQZGtlB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}